{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample Fruad=1 Class\n",
    "- Train using Keras DNN\n",
    "- Memory Reduction Reference: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v1.version' from '/home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/_api/v1/version/__init__.py'>\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "!python -c 'import tensorflow as tf; print(tf.version)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_features(df):\n",
    "    string_features = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.dtype('object'):\n",
    "            string_features.append(col)\n",
    "\n",
    "    return string_features\n",
    "\n",
    "\n",
    "def read_data(filename='./datasets/train_transaction.csv', drop_string_features=True):\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    if drop_string_features:\n",
    "        string_features = get_string_features(df)\n",
    "        df = df.drop(columns=string_features)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 3.46 s, total: 25.9 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%time train = read_data(drop_string_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 380)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Columns: 380 entries, TransactionID to V339\n",
      "dtypes: float64(376), int64(4)\n",
      "memory usage: 1.7 GB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>13926</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt  card1  card2  card3  \\\n",
       "0        2987000        0          86400            68.5  13926 -999.0  150.0   \n",
       "1        2987001        0          86401            29.0   2755  404.0  150.0   \n",
       "2        2987002        0          86469            59.0   4663  490.0  150.0   \n",
       "3        2987003        0          86499            50.0  18132  567.0  150.0   \n",
       "4        2987004        0          86506            50.0   4497  514.0  150.0   \n",
       "\n",
       "   card5  addr1  addr2  ...   V330   V331   V332   V333   V334   V335   V336  \\\n",
       "0  142.0  315.0   87.0  ... -999.0 -999.0 -999.0 -999.0 -999.0 -999.0 -999.0   \n",
       "1  102.0  325.0   87.0  ... -999.0 -999.0 -999.0 -999.0 -999.0 -999.0 -999.0   \n",
       "2  166.0  330.0   87.0  ... -999.0 -999.0 -999.0 -999.0 -999.0 -999.0 -999.0   \n",
       "3  117.0  476.0   87.0  ... -999.0 -999.0 -999.0 -999.0 -999.0 -999.0 -999.0   \n",
       "4  102.0  420.0   87.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "    V337   V338   V339  \n",
       "0 -999.0 -999.0 -999.0  \n",
       "1 -999.0 -999.0 -999.0  \n",
       "2 -999.0 -999.0 -999.0  \n",
       "3 -999.0 -999.0 -999.0  \n",
       "4    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 380 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1712.08 MB\n",
      "Memory usage after optimization is: 479.27 MB\n",
      "Decreased by 72.0%\n",
      "CPU times: user 1min, sys: 2min 28s, total: 3min 28s\n",
      "Wall time: 3min 28s\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Columns: 380 entries, TransactionID to V339\n",
      "dtypes: float16(332), float32(44), int16(1), int32(2), int8(1)\n",
      "memory usage: 479.3 MB\n"
     ]
    }
   ],
   "source": [
    "%time train = reduce_mem_usage(train)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_minority(df, random_state=27):\n",
    "    \"\"\"\n",
    "    Upsample minority class (isFraud=1), combine with majority class, and then shuffle them.\n",
    "    \"\"\"\n",
    "    \n",
    "    minority = df[df['isFraud']==1]\n",
    "    majority = df[df['isFraud']==0]\n",
    "    \n",
    "    minority_upsampled = resample(minority,\n",
    "                                 replace=True, # sample with replacement\n",
    "                                 n_samples=len(majority), # the size of Fraud equals to non-Fruad\n",
    "                                 random_state=random_state)\n",
    "    \n",
    "    df = pd.concat([majority, \n",
    "                    minority_upsampled])\n",
    "    \n",
    "    return shuffle(df, random_state=random_state)\n",
    "\n",
    "\n",
    "train_resampled = upsample_minority(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1139754, 380)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    569877\n",
       "0    569877\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_resampled.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, is_test_dataset=False):\n",
    "    if is_test_dataset:\n",
    "        return df.drop(columns=['TransactionID', 'TransactionDT'])\n",
    "    else:\n",
    "        return df.drop(columns=['isFraud', 'TransactionID', 'TransactionDT']), df['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess(train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(-999)\n",
    "y = y.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "del train_resampled\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0801 10:26:35.398051 140173097551552 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0801 10:26:35.420169 140173097551552 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0801 10:26:35.427523 140173097551552 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0801 10:26:35.507461 140173097551552 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0801 10:26:35.525628 140173097551552 deprecation.py:506] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0801 10:26:35.996976 140173097551552 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0801 10:26:36.002273 140173097551552 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0801 10:26:36.006527 140173097551552 deprecation.py:323] From /home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               96768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 142,689\n",
      "Trainable params: 141,681\n",
      "Non-trainable params: 1,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(input_dim, lr=1e-3):\n",
    "    \n",
    "#     inputs = keras.layers.Input(shape=[input_dim,])\n",
    "    \n",
    "#     x = keras.layers.Dense(256, activation='relu')(inputs)\n",
    "#     x = keras.layers.Dense(128, activation='relu')(x)\n",
    "#     x = keras.layers.Dense(64, activation='relu')(x)\n",
    "#     x = keras.layers.Dense(16, activation='relu')(x)\n",
    "#     outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "#     model = keras.models.Model(inputs=inputs,\n",
    "#                               outputs=outputs)\n",
    "    \n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer = 'uniform', input_dim=input_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer = 'uniform'))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model(X.shape[1], lr=1e-3)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1139754/1139754 [==============================] - 70s 61us/step - loss: 0.5244 - acc: 0.7414\n",
      "Epoch 2/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.5008 - acc: 0.7573\n",
      "Epoch 3/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.4910 - acc: 0.7631\n",
      "Epoch 4/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.4858 - acc: 0.7653\n",
      "Epoch 5/100\n",
      "1139754/1139754 [==============================] - 72s 63us/step - loss: 0.4787 - acc: 0.7697\n",
      "Epoch 6/100\n",
      "1139754/1139754 [==============================] - 72s 63us/step - loss: 0.4741 - acc: 0.7722\n",
      "Epoch 7/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4692 - acc: 0.7754\n",
      "Epoch 8/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4650 - acc: 0.7778\n",
      "Epoch 9/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4612 - acc: 0.7800\n",
      "Epoch 10/100\n",
      "1139754/1139754 [==============================] - 72s 63us/step - loss: 0.4588 - acc: 0.7813\n",
      "Epoch 11/100\n",
      "1139754/1139754 [==============================] - 73s 64us/step - loss: 0.4555 - acc: 0.7834\n",
      "Epoch 12/100\n",
      "1139754/1139754 [==============================] - 73s 64us/step - loss: 0.4524 - acc: 0.7853\n",
      "Epoch 13/100\n",
      "1139754/1139754 [==============================] - 71s 63us/step - loss: 0.4501 - acc: 0.7863\n",
      "Epoch 14/100\n",
      "1139754/1139754 [==============================] - 72s 63us/step - loss: 0.4472 - acc: 0.7883\n",
      "Epoch 15/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4478 - acc: 0.7879\n",
      "Epoch 16/100\n",
      "1139754/1139754 [==============================] - 73s 64us/step - loss: 0.4433 - acc: 0.7904\n",
      "Epoch 17/100\n",
      "1139754/1139754 [==============================] - 71s 63us/step - loss: 0.4396 - acc: 0.7924\n",
      "Epoch 18/100\n",
      "1139754/1139754 [==============================] - 72s 63us/step - loss: 0.4367 - acc: 0.7937\n",
      "Epoch 19/100\n",
      "1139754/1139754 [==============================] - 73s 64us/step - loss: 0.4352 - acc: 0.7947\n",
      "Epoch 20/100\n",
      "1139754/1139754 [==============================] - 74s 65us/step - loss: 0.4327 - acc: 0.7961\n",
      "Epoch 21/100\n",
      "1139754/1139754 [==============================] - 74s 65us/step - loss: 0.4325 - acc: 0.7960\n",
      "Epoch 22/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4314 - acc: 0.7970\n",
      "Epoch 23/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4295 - acc: 0.7983\n",
      "Epoch 24/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4274 - acc: 0.7992\n",
      "Epoch 25/100\n",
      "1139754/1139754 [==============================] - 72s 63us/step - loss: 0.4262 - acc: 0.7998\n",
      "Epoch 26/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4247 - acc: 0.8005\n",
      "Epoch 27/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4285 - acc: 0.7981\n",
      "Epoch 28/100\n",
      "1139754/1139754 [==============================] - 71s 62us/step - loss: 0.4271 - acc: 0.7995\n",
      "Epoch 29/100\n",
      "1139754/1139754 [==============================] - 70s 62us/step - loss: 0.4254 - acc: 0.8003\n",
      "Epoch 30/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.4229 - acc: 0.8012\n",
      "Epoch 31/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.4209 - acc: 0.8024\n",
      "Epoch 32/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.4203 - acc: 0.8027\n",
      "Epoch 33/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.4183 - acc: 0.8039\n",
      "Epoch 34/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.4175 - acc: 0.8043\n",
      "Epoch 35/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.4153 - acc: 0.8050\n",
      "Epoch 36/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.4124 - acc: 0.8070\n",
      "Epoch 37/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.4108 - acc: 0.8079\n",
      "Epoch 38/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.4092 - acc: 0.8088\n",
      "Epoch 39/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.4087 - acc: 0.8087\n",
      "Epoch 40/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.4074 - acc: 0.8097\n",
      "Epoch 41/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.4057 - acc: 0.8109\n",
      "Epoch 42/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.4042 - acc: 0.8114\n",
      "Epoch 43/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.4029 - acc: 0.8122\n",
      "Epoch 44/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.4023 - acc: 0.8123\n",
      "Epoch 45/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.4004 - acc: 0.8134\n",
      "Epoch 46/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.4002 - acc: 0.8137\n",
      "Epoch 47/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3989 - acc: 0.8143\n",
      "Epoch 48/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.3980 - acc: 0.8145\n",
      "Epoch 49/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3973 - acc: 0.8153\n",
      "Epoch 50/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3966 - acc: 0.8156\n",
      "Epoch 51/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3971 - acc: 0.8152\n",
      "Epoch 52/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3949 - acc: 0.8164\n",
      "Epoch 53/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3937 - acc: 0.8171\n",
      "Epoch 54/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3923 - acc: 0.8180\n",
      "Epoch 55/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3909 - acc: 0.8189\n",
      "Epoch 56/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3911 - acc: 0.8188\n",
      "Epoch 57/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3903 - acc: 0.8192\n",
      "Epoch 58/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3896 - acc: 0.8199\n",
      "Epoch 59/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3884 - acc: 0.8206\n",
      "Epoch 60/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3884 - acc: 0.8202\n",
      "Epoch 61/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3870 - acc: 0.8210\n",
      "Epoch 62/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3860 - acc: 0.8217\n",
      "Epoch 63/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3851 - acc: 0.8223\n",
      "Epoch 64/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3837 - acc: 0.8228\n",
      "Epoch 65/100\n",
      "1139754/1139754 [==============================] - 66s 58us/step - loss: 0.3833 - acc: 0.8234\n",
      "Epoch 66/100\n",
      "1139754/1139754 [==============================] - 66s 58us/step - loss: 0.3832 - acc: 0.8230\n",
      "Epoch 67/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3842 - acc: 0.8228\n",
      "Epoch 68/100\n",
      "1139754/1139754 [==============================] - 66s 58us/step - loss: 0.3822 - acc: 0.8236\n",
      "Epoch 69/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3807 - acc: 0.8247\n",
      "Epoch 70/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3797 - acc: 0.8248\n",
      "Epoch 71/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3791 - acc: 0.8255\n",
      "Epoch 72/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3790 - acc: 0.8255\n",
      "Epoch 73/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3784 - acc: 0.8260\n",
      "Epoch 74/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3772 - acc: 0.8262\n",
      "Epoch 75/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3768 - acc: 0.8266\n",
      "Epoch 76/100\n",
      "1139754/1139754 [==============================] - 66s 58us/step - loss: 0.3767 - acc: 0.8273\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139754/1139754 [==============================] - 66s 58us/step - loss: 0.3759 - acc: 0.8275\n",
      "Epoch 78/100\n",
      "1139754/1139754 [==============================] - 66s 58us/step - loss: 0.3749 - acc: 0.8280\n",
      "Epoch 79/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3739 - acc: 0.8284\n",
      "Epoch 80/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3724 - acc: 0.8291\n",
      "Epoch 81/100\n",
      "1139754/1139754 [==============================] - 66s 58us/step - loss: 0.3723 - acc: 0.8295\n",
      "Epoch 82/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3714 - acc: 0.8300\n",
      "Epoch 83/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3706 - acc: 0.8307\n",
      "Epoch 84/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3708 - acc: 0.8301\n",
      "Epoch 85/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3696 - acc: 0.8311\n",
      "Epoch 86/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3694 - acc: 0.8308\n",
      "Epoch 87/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3687 - acc: 0.8318\n",
      "Epoch 88/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3680 - acc: 0.8319\n",
      "Epoch 89/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3673 - acc: 0.8323\n",
      "Epoch 90/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3662 - acc: 0.8328\n",
      "Epoch 91/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3664 - acc: 0.8327\n",
      "Epoch 92/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3662 - acc: 0.8326\n",
      "Epoch 93/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3658 - acc: 0.8332\n",
      "Epoch 94/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3680 - acc: 0.8321\n",
      "Epoch 95/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3677 - acc: 0.8319\n",
      "Epoch 96/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3671 - acc: 0.8322\n",
      "Epoch 97/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3660 - acc: 0.8326\n",
      "Epoch 98/100\n",
      "1139754/1139754 [==============================] - 67s 58us/step - loss: 0.3659 - acc: 0.8329\n",
      "Epoch 99/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3645 - acc: 0.8338\n",
      "Epoch 100/100\n",
      "1139754/1139754 [==============================] - 70s 61us/step - loss: 0.3639 - acc: 0.8338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c3c351978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "model.fit(X, y,\n",
    "         epochs=epochs,\n",
    "         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc score=0.9396283669312819\n"
     ]
    }
   ],
   "source": [
    "pred_prob = model.predict_proba(X,\n",
    "                               batch_size=batch_size)\n",
    "\n",
    "score = roc_auc_score(y, pred_prob)\n",
    "\n",
    "print('roc-auc score={}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/keras/dnn/transactions_all_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3631 - acc: 0.8342\n",
      "Epoch 2/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3629 - acc: 0.8346\n",
      "Epoch 3/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3629 - acc: 0.8346\n",
      "Epoch 4/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3624 - acc: 0.8353\n",
      "Epoch 5/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3617 - acc: 0.8355\n",
      "Epoch 6/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3623 - acc: 0.8351\n",
      "Epoch 7/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3615 - acc: 0.8355\n",
      "Epoch 8/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3612 - acc: 0.8356\n",
      "Epoch 9/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3603 - acc: 0.8360\n",
      "Epoch 10/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3600 - acc: 0.8362\n",
      "Epoch 11/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3591 - acc: 0.8365\n",
      "Epoch 12/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3591 - acc: 0.8368\n",
      "Epoch 13/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3589 - acc: 0.8372\n",
      "Epoch 14/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3586 - acc: 0.8375\n",
      "Epoch 15/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3585 - acc: 0.8376\n",
      "Epoch 16/100\n",
      "1139754/1139754 [==============================] - 70s 61us/step - loss: 0.3576 - acc: 0.8380\n",
      "Epoch 17/100\n",
      "1139754/1139754 [==============================] - 70s 62us/step - loss: 0.3569 - acc: 0.8382\n",
      "Epoch 18/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3570 - acc: 0.8384\n",
      "Epoch 19/100\n",
      "1139754/1139754 [==============================] - 70s 61us/step - loss: 0.3561 - acc: 0.8388\n",
      "Epoch 20/100\n",
      "1139754/1139754 [==============================] - 70s 61us/step - loss: 0.3554 - acc: 0.8393\n",
      "Epoch 21/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.3555 - acc: 0.8392\n",
      "Epoch 22/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3549 - acc: 0.8396\n",
      "Epoch 23/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3541 - acc: 0.8402\n",
      "Epoch 24/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.3548 - acc: 0.8397\n",
      "Epoch 25/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3537 - acc: 0.8402\n",
      "Epoch 26/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3531 - acc: 0.8406\n",
      "Epoch 27/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3526 - acc: 0.8409\n",
      "Epoch 28/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3517 - acc: 0.8415\n",
      "Epoch 29/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3529 - acc: 0.8408\n",
      "Epoch 30/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3521 - acc: 0.8411\n",
      "Epoch 31/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3524 - acc: 0.8410\n",
      "Epoch 32/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3514 - acc: 0.8413\n",
      "Epoch 33/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3514 - acc: 0.8415\n",
      "Epoch 34/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3507 - acc: 0.8423\n",
      "Epoch 35/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3503 - acc: 0.8423\n",
      "Epoch 36/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3500 - acc: 0.8425\n",
      "Epoch 37/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3495 - acc: 0.8427\n",
      "Epoch 38/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3489 - acc: 0.8432\n",
      "Epoch 39/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3490 - acc: 0.8429\n",
      "Epoch 40/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3492 - acc: 0.8432\n",
      "Epoch 41/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3489 - acc: 0.8430\n",
      "Epoch 42/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3481 - acc: 0.8430\n",
      "Epoch 43/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3481 - acc: 0.8434\n",
      "Epoch 44/100\n",
      "1139754/1139754 [==============================] - 70s 61us/step - loss: 0.3483 - acc: 0.8435\n",
      "Epoch 45/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3482 - acc: 0.8438\n",
      "Epoch 46/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3502 - acc: 0.8424\n",
      "Epoch 47/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3488 - acc: 0.8428\n",
      "Epoch 48/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.3476 - acc: 0.8437\n",
      "Epoch 49/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3473 - acc: 0.8439\n",
      "Epoch 50/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3461 - acc: 0.8447\n",
      "Epoch 51/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3465 - acc: 0.8446\n",
      "Epoch 52/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3467 - acc: 0.8444\n",
      "Epoch 53/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3462 - acc: 0.8449\n",
      "Epoch 54/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3455 - acc: 0.8451\n",
      "Epoch 55/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3442 - acc: 0.8459\n",
      "Epoch 56/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3451 - acc: 0.8456\n",
      "Epoch 57/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3443 - acc: 0.8460\n",
      "Epoch 58/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3446 - acc: 0.8453\n",
      "Epoch 59/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3443 - acc: 0.8455\n",
      "Epoch 60/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3431 - acc: 0.8465\n",
      "Epoch 61/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3441 - acc: 0.8458\n",
      "Epoch 62/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3433 - acc: 0.8464\n",
      "Epoch 63/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3425 - acc: 0.8474\n",
      "Epoch 64/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3439 - acc: 0.8458\n",
      "Epoch 65/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3427 - acc: 0.8469\n",
      "Epoch 66/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3421 - acc: 0.8474\n",
      "Epoch 67/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.3409 - acc: 0.8478\n",
      "Epoch 68/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3427 - acc: 0.8470\n",
      "Epoch 69/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3510 - acc: 0.8420\n",
      "Epoch 70/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3495 - acc: 0.8430\n",
      "Epoch 71/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3484 - acc: 0.8437\n",
      "Epoch 72/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3473 - acc: 0.8444\n",
      "Epoch 73/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3466 - acc: 0.8442\n",
      "Epoch 74/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.3471 - acc: 0.8445\n",
      "Epoch 75/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.3464 - acc: 0.8449\n",
      "Epoch 76/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3458 - acc: 0.8449\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3449 - acc: 0.8454\n",
      "Epoch 78/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3453 - acc: 0.8452\n",
      "Epoch 79/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3446 - acc: 0.8458\n",
      "Epoch 80/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3433 - acc: 0.8462\n",
      "Epoch 81/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3442 - acc: 0.8456\n",
      "Epoch 82/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3434 - acc: 0.8467\n",
      "Epoch 83/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3434 - acc: 0.8464\n",
      "Epoch 84/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3428 - acc: 0.8466\n",
      "Epoch 85/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3429 - acc: 0.8465\n",
      "Epoch 86/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3427 - acc: 0.8466\n",
      "Epoch 87/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3419 - acc: 0.8469\n",
      "Epoch 88/100\n",
      "1139754/1139754 [==============================] - 69s 61us/step - loss: 0.3416 - acc: 0.8471\n",
      "Epoch 89/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3413 - acc: 0.8473\n",
      "Epoch 90/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3411 - acc: 0.8475\n",
      "Epoch 91/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3411 - acc: 0.8474\n",
      "Epoch 92/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3408 - acc: 0.8479\n",
      "Epoch 93/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3399 - acc: 0.8479\n",
      "Epoch 94/100\n",
      "1139754/1139754 [==============================] - 68s 59us/step - loss: 0.3395 - acc: 0.8484\n",
      "Epoch 95/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3398 - acc: 0.8483\n",
      "Epoch 96/100\n",
      "1139754/1139754 [==============================] - 69s 60us/step - loss: 0.3387 - acc: 0.8487\n",
      "Epoch 97/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3391 - acc: 0.8484\n",
      "Epoch 98/100\n",
      "1139754/1139754 [==============================] - 67s 59us/step - loss: 0.3399 - acc: 0.8481\n",
      "Epoch 99/100\n",
      "1139754/1139754 [==============================] - 68s 60us/step - loss: 0.3394 - acc: 0.8483\n",
      "Epoch 100/100\n",
      "1139754/1139754 [==============================] - 70s 62us/step - loss: 0.3394 - acc: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c39bac780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "model.fit(X, y,\n",
    "         epochs=epochs,\n",
    "         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc score=0.9498802193771105\n"
     ]
    }
   ],
   "source": [
    "pred_prob = model.predict_proba(X,\n",
    "                               batch_size=batch_size)\n",
    "\n",
    "score = roc_auc_score(y, pred_prob)\n",
    "\n",
    "print('roc-auc score={}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/keras/dnn/transactions_all_epochs_200.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc score=0.9498802193771105\n"
     ]
    }
   ],
   "source": [
    "model_test = keras.models.load_model('./models/keras/dnn/transactions_all_epochs_200.h5')\n",
    "\n",
    "pred_prob = model_test.predict_proba(X,\n",
    "                               batch_size=batch_size)\n",
    "\n",
    "score = roc_auc_score(y, pred_prob)\n",
    "\n",
    "print('roc-auc score={}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.2 s, sys: 3.13 s, total: 23.3 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%time test = read_data(filename='./datasets/test_transaction.csv', drop_string_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 379)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1465.12 MB\n",
      "Memory usage after optimization is: 418.47 MB\n",
      "Decreased by 71.4%\n",
      "CPU times: user 53.7 s, sys: 2min 4s, total: 2min 58s\n",
      "Wall time: 2min 58s\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506691 entries, 0 to 506690\n",
      "Columns: 379 entries, TransactionID to V339\n",
      "dtypes: float16(324), float32(52), int16(1), int32(2)\n",
      "memory usage: 418.5 MB\n"
     ]
    }
   ],
   "source": [
    "%time test = reduce_mem_usage(test)\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess(test, is_test_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "model_test = keras.models.load_model('./models/keras/dnn/transactions_all_epochs_200.h5')\n",
    "\n",
    "pred_prob = model_test.predict_proba(X,\n",
    "                               batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_df = pd.DataFrame(test['TransactionID'], columns=['TransactionID'])\n",
    "test_result_df['isFraud'] = pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>0.008168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>0.008616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>0.053845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>0.172444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>0.031337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.008168\n",
       "1        3663550  0.008616\n",
       "2        3663551  0.053845\n",
       "3        3663552  0.172444\n",
       "4        3663553  0.031337"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_df.to_csv('./prediction_test_dnn_epochs_200_2019_0801.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
