{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample Fruad=1 Class\n",
    "- Train using Keras DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v1.version' from '/home/ec2-user/anaconda3/lib/python3.7/site-packages/tensorflow/_api/v1/version/__init__.py'>\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "!python -c 'import tensorflow as tf; print(tf.version)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_features(df):\n",
    "    string_features = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.dtype('object'):\n",
    "            string_features.append(col)\n",
    "\n",
    "    return string_features\n",
    "\n",
    "\n",
    "def read_data(drop_string_features=True):\n",
    "    \n",
    "    df = pd.read_csv('./datasets/kfold/transaction_fold_0_0_0.csv')\n",
    "    \n",
    "    if drop_string_features:\n",
    "        string_features = get_string_features(df)\n",
    "        df = df.drop(columns=string_features)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "train = read_data(drop_string_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73816, 380)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_minority(df, random_state=27):\n",
    "    \"\"\"\n",
    "    Upsample minority class (isFraud=1), combine with majority class, and then shuffle them.\n",
    "    \"\"\"\n",
    "    \n",
    "    minority = df[df['isFraud']==1]\n",
    "    majority = df[df['isFraud']==0]\n",
    "    \n",
    "    minority_upsampled = resample(minority,\n",
    "                                 replace=True, # sample with replacement\n",
    "                                 n_samples=len(majority), # the size of Fraud equals to non-Fruad\n",
    "                                 random_state=random_state)\n",
    "    \n",
    "    df = pd.concat([majority, \n",
    "                    minority_upsampled])\n",
    "    \n",
    "    return shuffle(df, random_state=random_state)\n",
    "\n",
    "\n",
    "train_resampled = upsample_minority(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142752, 380)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71376\n",
       "0    71376\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_resampled.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    return df.drop(columns=['isFraud', 'TransactionID', 'TransactionDT']), df['isFraud']\n",
    "\n",
    "\n",
    "X, y = preprocess(train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(-999)\n",
    "y = y.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "del train_resampled\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 256)               96768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 142,689\n",
      "Trainable params: 141,681\n",
      "Non-trainable params: 1,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model(input_dim, lr=1e-3):\n",
    "    \n",
    "#     inputs = keras.layers.Input(shape=[input_dim,])\n",
    "    \n",
    "#     x = keras.layers.Dense(256, activation='relu')(inputs)\n",
    "#     x = keras.layers.Dense(128, activation='relu')(x)\n",
    "#     x = keras.layers.Dense(64, activation='relu')(x)\n",
    "#     x = keras.layers.Dense(16, activation='relu')(x)\n",
    "#     outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "#     model = keras.models.Model(inputs=inputs,\n",
    "#                               outputs=outputs)\n",
    "    \n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer = 'uniform', input_dim=input_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer = 'uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer = 'uniform'))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model(X.shape[1], lr=1e-3)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "142752/142752 [==============================] - 9s 65us/step - loss: 0.5573 - acc: 0.7217\n",
      "Epoch 2/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.5188 - acc: 0.7455\n",
      "Epoch 3/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.5109 - acc: 0.7498\n",
      "Epoch 4/50\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.5035 - acc: 0.7535\n",
      "Epoch 5/50\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.4978 - acc: 0.7586\n",
      "Epoch 6/50\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.4920 - acc: 0.7625\n",
      "Epoch 7/50\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.4883 - acc: 0.7638\n",
      "Epoch 8/50\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.4846 - acc: 0.7664\n",
      "Epoch 9/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4782 - acc: 0.7703\n",
      "Epoch 10/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4763 - acc: 0.7715\n",
      "Epoch 11/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4729 - acc: 0.7738\n",
      "Epoch 12/50\n",
      "142752/142752 [==============================] - 7s 53us/step - loss: 0.4701 - acc: 0.7752\n",
      "Epoch 13/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4684 - acc: 0.7748\n",
      "Epoch 14/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4669 - acc: 0.7781\n",
      "Epoch 15/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4618 - acc: 0.7800\n",
      "Epoch 16/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4580 - acc: 0.7831\n",
      "Epoch 17/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4532 - acc: 0.7838\n",
      "Epoch 18/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4488 - acc: 0.7877\n",
      "Epoch 19/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4467 - acc: 0.7883\n",
      "Epoch 20/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4445 - acc: 0.7898\n",
      "Epoch 21/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4424 - acc: 0.7914\n",
      "Epoch 22/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4412 - acc: 0.7912\n",
      "Epoch 23/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4378 - acc: 0.7938\n",
      "Epoch 24/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4380 - acc: 0.7944\n",
      "Epoch 25/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4370 - acc: 0.7948\n",
      "Epoch 26/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4309 - acc: 0.7979\n",
      "Epoch 27/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4288 - acc: 0.7983\n",
      "Epoch 28/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4277 - acc: 0.7983\n",
      "Epoch 29/50\n",
      "142752/142752 [==============================] - 7s 53us/step - loss: 0.4232 - acc: 0.8031\n",
      "Epoch 30/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4213 - acc: 0.8039\n",
      "Epoch 31/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4189 - acc: 0.8048\n",
      "Epoch 32/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4172 - acc: 0.8046\n",
      "Epoch 33/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4193 - acc: 0.8050\n",
      "Epoch 34/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4158 - acc: 0.8050\n",
      "Epoch 35/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4147 - acc: 0.8060\n",
      "Epoch 36/50\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.4109 - acc: 0.8090\n",
      "Epoch 37/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4085 - acc: 0.8108\n",
      "Epoch 38/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.4084 - acc: 0.8096\n",
      "Epoch 39/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4073 - acc: 0.8094\n",
      "Epoch 40/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4062 - acc: 0.8117\n",
      "Epoch 41/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.4014 - acc: 0.8129\n",
      "Epoch 42/50\n",
      "142752/142752 [==============================] - 7s 53us/step - loss: 0.4008 - acc: 0.8140\n",
      "Epoch 43/50\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3989 - acc: 0.8148\n",
      "Epoch 44/50\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3986 - acc: 0.8159\n",
      "Epoch 45/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3975 - acc: 0.8159\n",
      "Epoch 46/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3975 - acc: 0.8167\n",
      "Epoch 47/50\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3923 - acc: 0.8182\n",
      "Epoch 48/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3902 - acc: 0.8204\n",
      "Epoch 49/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3875 - acc: 0.8207\n",
      "Epoch 50/50\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3884 - acc: 0.8199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c440b1400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "\n",
    "model.fit(X, y,\n",
    "         epochs=epochs,\n",
    "         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc score=0.9119878328578055\n"
     ]
    }
   ],
   "source": [
    "pred_prob = model.predict_proba(X,\n",
    "                               batch_size=batch_size)\n",
    "\n",
    "score = roc_auc_score(y, pred_prob)\n",
    "\n",
    "print('roc-auc score={}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3875 - acc: 0.8209\n",
      "Epoch 2/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3851 - acc: 0.8210\n",
      "Epoch 3/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3855 - acc: 0.8216\n",
      "Epoch 4/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3822 - acc: 0.8242\n",
      "Epoch 5/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3832 - acc: 0.8231\n",
      "Epoch 6/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3824 - acc: 0.8234\n",
      "Epoch 7/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3797 - acc: 0.8248\n",
      "Epoch 8/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3779 - acc: 0.8262\n",
      "Epoch 9/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3777 - acc: 0.8264\n",
      "Epoch 10/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3766 - acc: 0.8280\n",
      "Epoch 11/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3748 - acc: 0.8284\n",
      "Epoch 12/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3740 - acc: 0.8278\n",
      "Epoch 13/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3747 - acc: 0.8284\n",
      "Epoch 14/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3753 - acc: 0.8274\n",
      "Epoch 15/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3711 - acc: 0.8291\n",
      "Epoch 16/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3707 - acc: 0.8286\n",
      "Epoch 17/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3693 - acc: 0.8309\n",
      "Epoch 18/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3684 - acc: 0.8319\n",
      "Epoch 19/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3670 - acc: 0.8312\n",
      "Epoch 20/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3655 - acc: 0.8338\n",
      "Epoch 21/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3685 - acc: 0.8313\n",
      "Epoch 22/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3629 - acc: 0.8342\n",
      "Epoch 23/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3604 - acc: 0.8350\n",
      "Epoch 24/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3618 - acc: 0.8350\n",
      "Epoch 25/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3597 - acc: 0.8365\n",
      "Epoch 26/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3597 - acc: 0.8365\n",
      "Epoch 27/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3595 - acc: 0.8360\n",
      "Epoch 28/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3571 - acc: 0.8374\n",
      "Epoch 29/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3591 - acc: 0.8363\n",
      "Epoch 30/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3604 - acc: 0.8353\n",
      "Epoch 31/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3578 - acc: 0.8373\n",
      "Epoch 32/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3561 - acc: 0.8385\n",
      "Epoch 33/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3557 - acc: 0.8386\n",
      "Epoch 34/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3556 - acc: 0.8376\n",
      "Epoch 35/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3544 - acc: 0.8380\n",
      "Epoch 36/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3521 - acc: 0.8398\n",
      "Epoch 37/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3520 - acc: 0.8402\n",
      "Epoch 38/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3528 - acc: 0.8396\n",
      "Epoch 39/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3506 - acc: 0.8409\n",
      "Epoch 40/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3487 - acc: 0.8419\n",
      "Epoch 41/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3478 - acc: 0.8419\n",
      "Epoch 42/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3462 - acc: 0.8435\n",
      "Epoch 43/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3469 - acc: 0.8431\n",
      "Epoch 44/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3486 - acc: 0.8419\n",
      "Epoch 45/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3486 - acc: 0.8419\n",
      "Epoch 46/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3451 - acc: 0.8431\n",
      "Epoch 47/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3467 - acc: 0.8440\n",
      "Epoch 48/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3446 - acc: 0.8441\n",
      "Epoch 49/100\n",
      "142752/142752 [==============================] - 7s 53us/step - loss: 0.3416 - acc: 0.8451\n",
      "Epoch 50/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3408 - acc: 0.8461\n",
      "Epoch 51/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3412 - acc: 0.8451\n",
      "Epoch 52/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3387 - acc: 0.8467\n",
      "Epoch 53/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3402 - acc: 0.8465\n",
      "Epoch 54/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3381 - acc: 0.8471\n",
      "Epoch 55/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3390 - acc: 0.8459\n",
      "Epoch 56/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3372 - acc: 0.8480\n",
      "Epoch 57/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3352 - acc: 0.8485\n",
      "Epoch 58/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3363 - acc: 0.8477\n",
      "Epoch 59/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3338 - acc: 0.8494\n",
      "Epoch 60/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3352 - acc: 0.8489\n",
      "Epoch 61/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3321 - acc: 0.8496\n",
      "Epoch 62/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3308 - acc: 0.8502\n",
      "Epoch 63/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3335 - acc: 0.8490\n",
      "Epoch 64/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3321 - acc: 0.8496\n",
      "Epoch 65/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3308 - acc: 0.8505\n",
      "Epoch 66/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3317 - acc: 0.8504\n",
      "Epoch 67/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3291 - acc: 0.8503\n",
      "Epoch 68/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3308 - acc: 0.8520\n",
      "Epoch 69/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3282 - acc: 0.8516\n",
      "Epoch 70/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3254 - acc: 0.8545\n",
      "Epoch 71/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3280 - acc: 0.8519\n",
      "Epoch 72/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3243 - acc: 0.8536\n",
      "Epoch 73/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3263 - acc: 0.8527\n",
      "Epoch 74/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3242 - acc: 0.8540\n",
      "Epoch 75/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3237 - acc: 0.8548\n",
      "Epoch 76/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3239 - acc: 0.8546\n",
      "Epoch 77/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3238 - acc: 0.8537\n",
      "Epoch 78/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3223 - acc: 0.8550\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3230 - acc: 0.8549\n",
      "Epoch 80/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3228 - acc: 0.8560\n",
      "Epoch 81/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3228 - acc: 0.8556\n",
      "Epoch 82/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3224 - acc: 0.8549\n",
      "Epoch 83/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3196 - acc: 0.8568\n",
      "Epoch 84/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3199 - acc: 0.8563\n",
      "Epoch 85/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3198 - acc: 0.8561\n",
      "Epoch 86/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3197 - acc: 0.8569\n",
      "Epoch 87/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3174 - acc: 0.8578\n",
      "Epoch 88/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3181 - acc: 0.8565\n",
      "Epoch 89/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3168 - acc: 0.8569\n",
      "Epoch 90/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3171 - acc: 0.8579\n",
      "Epoch 91/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3160 - acc: 0.8600\n",
      "Epoch 92/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3148 - acc: 0.8587\n",
      "Epoch 93/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3166 - acc: 0.8574\n",
      "Epoch 94/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.3137 - acc: 0.8596\n",
      "Epoch 95/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3128 - acc: 0.8597\n",
      "Epoch 96/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3124 - acc: 0.8606\n",
      "Epoch 97/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3129 - acc: 0.8604\n",
      "Epoch 98/100\n",
      "142752/142752 [==============================] - 8s 56us/step - loss: 0.3109 - acc: 0.8612\n",
      "Epoch 99/100\n",
      "142752/142752 [==============================] - 8s 56us/step - loss: 0.3092 - acc: 0.8621\n",
      "Epoch 100/100\n",
      "142752/142752 [==============================] - 8s 56us/step - loss: 0.3091 - acc: 0.8618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c0def1be0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "model.fit(X, y,\n",
    "         epochs=epochs,\n",
    "         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc score=0.9688005728358191\n"
     ]
    }
   ],
   "source": [
    "pred_prob = model.predict_proba(X,\n",
    "                               batch_size=batch_size)\n",
    "\n",
    "score = roc_auc_score(y, pred_prob)\n",
    "\n",
    "print('roc-auc score={}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "142752/142752 [==============================] - 8s 55us/step - loss: 0.3087 - acc: 0.8615\n",
      "Epoch 2/100\n",
      "142752/142752 [==============================] - 8s 55us/step - loss: 0.3093 - acc: 0.8620\n",
      "Epoch 3/100\n",
      "142752/142752 [==============================] - 8s 55us/step - loss: 0.3076 - acc: 0.8617\n",
      "Epoch 4/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3088 - acc: 0.8618\n",
      "Epoch 5/100\n",
      "142752/142752 [==============================] - 8s 56us/step - loss: 0.3081 - acc: 0.8629\n",
      "Epoch 6/100\n",
      "142752/142752 [==============================] - 8s 56us/step - loss: 0.3068 - acc: 0.8624\n",
      "Epoch 7/100\n",
      "142752/142752 [==============================] - 8s 57us/step - loss: 0.3065 - acc: 0.8617\n",
      "Epoch 8/100\n",
      "142752/142752 [==============================] - 8s 56us/step - loss: 0.3054 - acc: 0.8639\n",
      "Epoch 9/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3044 - acc: 0.8634\n",
      "Epoch 10/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3049 - acc: 0.8634\n",
      "Epoch 11/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3022 - acc: 0.8645\n",
      "Epoch 12/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3010 - acc: 0.8667\n",
      "Epoch 13/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3011 - acc: 0.8645\n",
      "Epoch 14/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3015 - acc: 0.8654\n",
      "Epoch 15/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3016 - acc: 0.8651\n",
      "Epoch 16/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3003 - acc: 0.8657\n",
      "Epoch 17/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3036 - acc: 0.8637\n",
      "Epoch 18/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3025 - acc: 0.8644\n",
      "Epoch 19/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2998 - acc: 0.8665\n",
      "Epoch 20/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2999 - acc: 0.8664\n",
      "Epoch 21/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3000 - acc: 0.8658\n",
      "Epoch 22/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2998 - acc: 0.8666\n",
      "Epoch 23/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3003 - acc: 0.8665\n",
      "Epoch 24/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3026 - acc: 0.8656\n",
      "Epoch 25/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3000 - acc: 0.8666\n",
      "Epoch 26/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.3017 - acc: 0.8657\n",
      "Epoch 27/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3016 - acc: 0.8654\n",
      "Epoch 28/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3017 - acc: 0.8655\n",
      "Epoch 29/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.3000 - acc: 0.8664\n",
      "Epoch 30/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2987 - acc: 0.8679\n",
      "Epoch 31/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2976 - acc: 0.8685\n",
      "Epoch 32/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2981 - acc: 0.8672\n",
      "Epoch 33/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2938 - acc: 0.8693\n",
      "Epoch 34/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2948 - acc: 0.8686\n",
      "Epoch 35/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2962 - acc: 0.8682\n",
      "Epoch 36/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2951 - acc: 0.8685\n",
      "Epoch 37/100\n",
      "142752/142752 [==============================] - 8s 55us/step - loss: 0.2946 - acc: 0.8695\n",
      "Epoch 38/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2951 - acc: 0.8688\n",
      "Epoch 39/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2930 - acc: 0.8699\n",
      "Epoch 40/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2941 - acc: 0.8699\n",
      "Epoch 41/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2943 - acc: 0.8689\n",
      "Epoch 42/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2935 - acc: 0.8699\n",
      "Epoch 43/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2964 - acc: 0.8688\n",
      "Epoch 44/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2908 - acc: 0.8711\n",
      "Epoch 45/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.2917 - acc: 0.8700\n",
      "Epoch 46/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2907 - acc: 0.8706\n",
      "Epoch 47/100\n",
      "142752/142752 [==============================] - 8s 55us/step - loss: 0.2916 - acc: 0.8697\n",
      "Epoch 48/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2900 - acc: 0.8715\n",
      "Epoch 49/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2901 - acc: 0.8720\n",
      "Epoch 50/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2888 - acc: 0.8708\n",
      "Epoch 51/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2913 - acc: 0.8704\n",
      "Epoch 52/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2904 - acc: 0.8708\n",
      "Epoch 53/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2916 - acc: 0.8710\n",
      "Epoch 54/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2884 - acc: 0.8736\n",
      "Epoch 55/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2875 - acc: 0.8731\n",
      "Epoch 56/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2876 - acc: 0.8735\n",
      "Epoch 57/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2895 - acc: 0.8728\n",
      "Epoch 58/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2873 - acc: 0.8734\n",
      "Epoch 59/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2872 - acc: 0.8732\n",
      "Epoch 60/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2884 - acc: 0.8730\n",
      "Epoch 61/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2879 - acc: 0.8729\n",
      "Epoch 62/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.2868 - acc: 0.8738\n",
      "Epoch 63/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2885 - acc: 0.8720\n",
      "Epoch 64/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2866 - acc: 0.8733\n",
      "Epoch 65/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2853 - acc: 0.8748\n",
      "Epoch 66/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2852 - acc: 0.8733\n",
      "Epoch 67/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2854 - acc: 0.8741\n",
      "Epoch 68/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2864 - acc: 0.8749\n",
      "Epoch 69/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2846 - acc: 0.8741\n",
      "Epoch 70/100\n",
      "142752/142752 [==============================] - 8s 55us/step - loss: 0.2856 - acc: 0.8737\n",
      "Epoch 71/100\n",
      "142752/142752 [==============================] - 8s 55us/step - loss: 0.2833 - acc: 0.8749\n",
      "Epoch 72/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2871 - acc: 0.8726\n",
      "Epoch 73/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2835 - acc: 0.8747\n",
      "Epoch 74/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2842 - acc: 0.8750\n",
      "Epoch 75/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2833 - acc: 0.8757\n",
      "Epoch 76/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2815 - acc: 0.8760\n",
      "Epoch 77/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2817 - acc: 0.8754\n",
      "Epoch 78/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2819 - acc: 0.8758\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2827 - acc: 0.8752\n",
      "Epoch 80/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2831 - acc: 0.8753\n",
      "Epoch 81/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2822 - acc: 0.8754\n",
      "Epoch 82/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2824 - acc: 0.8757\n",
      "Epoch 83/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2831 - acc: 0.8754\n",
      "Epoch 84/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2794 - acc: 0.8766\n",
      "Epoch 85/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2792 - acc: 0.8775\n",
      "Epoch 86/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2802 - acc: 0.8764\n",
      "Epoch 87/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2789 - acc: 0.8782\n",
      "Epoch 88/100\n",
      "142752/142752 [==============================] - 8s 54us/step - loss: 0.2796 - acc: 0.8773\n",
      "Epoch 89/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2805 - acc: 0.8777\n",
      "Epoch 90/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2787 - acc: 0.8772\n",
      "Epoch 91/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2795 - acc: 0.8772\n",
      "Epoch 92/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2806 - acc: 0.8769\n",
      "Epoch 93/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.2804 - acc: 0.8762\n",
      "Epoch 94/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2767 - acc: 0.8790\n",
      "Epoch 95/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.2811 - acc: 0.8770\n",
      "Epoch 96/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.2777 - acc: 0.8786\n",
      "Epoch 97/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.2782 - acc: 0.8779\n",
      "Epoch 98/100\n",
      "142752/142752 [==============================] - 7s 52us/step - loss: 0.2809 - acc: 0.8761\n",
      "Epoch 99/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2795 - acc: 0.8765\n",
      "Epoch 100/100\n",
      "142752/142752 [==============================] - 8s 53us/step - loss: 0.2789 - acc: 0.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c0df3b828>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "model.fit(X, y,\n",
    "         epochs=epochs,\n",
    "         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc score=0.9773538543208868\n"
     ]
    }
   ],
   "source": [
    "pred_prob = model.predict_proba(X,\n",
    "                               batch_size=batch_size)\n",
    "\n",
    "score = roc_auc_score(y, pred_prob)\n",
    "\n",
    "print('roc-auc score={}'.format(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 1.31 s, total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, n_thread=2, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=27, silent=None, subsample=1,\n",
       "       verbosity=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 27\n",
    "model = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            n_thread=cpu_count(),\n",
    "                            seed=seed)\n",
    "\n",
    "%time model.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc score=0.9118305454399285\n"
     ]
    }
   ],
   "source": [
    "pred_prob = model.predict_proba(X)\n",
    "\n",
    "score = roc_auc_score(y, pred_prob[:, 1])\n",
    "\n",
    "print('roc-auc score={}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc score=0.9125657594645398\n"
     ]
    }
   ],
   "source": [
    "X_org, y_org = preprocess(train)\n",
    "\n",
    "pred_prob = model.predict_proba(X_org)\n",
    "\n",
    "score = roc_auc_score(y_org, pred_prob[:, 1])\n",
    "\n",
    "print('roc-auc score={}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
